{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e573af75",
   "metadata": {},
   "source": [
    "# Visualization & Diagnostics\n",
    "\n",
    "This notebook reproduces the visualization portion of the project: data inspection, distribution plots, correlation, dimensionality reduction (PCA/t-SNE/UMAP), feature importance and model evaluation visualizations.\n",
    "\n",
    "Notes: run top-to-bottom. The notebook uses sampled data for heavy operations (PCA/t-SNE/UMAP/SHAP) to remain interactive. Figures are saved to `results/figs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee04c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
    "import joblib\n",
    "\n",
    "# Optional imports for UMAP/plotly/SHAP\n",
    "try:\n",
    "    import umap\n",
    "except Exception:\n",
    "    umap = None\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "except Exception:\n",
    "    px = None; go = None\n",
    "\n",
    "ROOT = Path('..').resolve().parents[0] if False else Path(__file__).resolve().parents[2] if '__file__' in globals() else Path('c:/ECHO/Projects/Personal_Projects/Fruty')\n",
    "ROOT = Path('c:/ECHO/Projects/Personal_Projects/Fruty')\n",
    "DATA_PATH = ROOT / 'combine.csv'\n",
    "RESULTS = ROOT / 'results'\n",
    "FIG_DIR = RESULTS / 'figs'\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb34f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load permutation checks results (if available) and print top features\n",
    "checks_path = RESULTS / 'catboost_checks.json'\n",
    "perm_top = []\n",
    "if checks_path.exists():\n",
    "    js = json.loads(checks_path.read_text())\n",
    "    perm_top = js.get('top_perm_features', js.get('top_permutation_features') or js.get('top_features') or js.get('top_features_perm', []))\n",
    "    # catboost_checks from earlier stored 'Top perm features' in summary; try fallback\n",
    "    if not perm_top and 'permutation_importance' in js:\n",
    "        # expect list of (feature, score)\n",
    "        perm = js.get('permutation_importance')\n",
    "        perm_top = [f for f,s in perm][:10]\n",
    "    print('Loaded catboost_checks.json, top perm features (sample):', perm_top[:10])\n",
    "else:\n",
    "    print('No catboost_checks.json found; top features will be inferred from model or variance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final model bundle\n",
    "model_path = ROOT / 'models' / 'final_detector.joblib'\n",
    "if not model_path.exists():\n",
    "    raise FileNotFoundError(f'Final model not found at {model_path}')\n",
    "bundle = joblib.load(model_path)\n",
    "clf = bundle.get('catboost') or bundle.get('model') or bundle.get('clf')\n",
    "cat_features = bundle.get('cat_features', [])\n",
    "threshold = float(bundle.get('threshold', 0.5))\n",
    "print('Loaded model:', type(clf).__name__, 'threshold=', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: read a sampled chunk-friendly DataFrame (sample up to n rows)\n",
    "def load_sample_csv(path, n=100000, random_state=42):\n",
    "    # try fast read + sample if too large\n",
    "    # if file smaller than n*2, load full\n",
    "    import os\n",
    "    try:\n",
    "        total = os.path.getsize(path)\n",
    "    except Exception:\n",
    "        total = None\n",
    "    # load with pandas but only first n*10 rows if size large to speed up\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    if len(df) > n:\n",
    "        return df.sample(n, random_state=random_state).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "print('Loading sample (may take a moment)')\n",
    "t0 = time.time()\n",
    "df_sample = load_sample_csv(DATA_PATH, n=100000)\n",
    "print('Loaded sample rows=', len(df_sample), 'in', round(time.time()-t0,2),'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data checks\n",
    "label_candidates = ['label','target','class','attack']\n",
    "label_col = None\n",
    "for c in label_candidates:\n",
    "    if c in df_sample.columns:\n",
    "        label_col = c\n",
    "        break\n",
    "if label_col is None:\n",
    "    label_col = df_sample.columns[-1]\n",
    "print('Using label column:', label_col)\n",
    "print('Shape:', df_sample.shape)\n",
    "display(df_sample.head())\n",
    "# missing value summary\n",
    "print('\n",
    "Missing values (top cols):')\n",
    "print(df_sample.isna().sum().sort_values(ascending=False).head(10))\n",
    "# class distribution\n",
    "print('\n",
    "Class counts:')\n",
    "print(df_sample[label_col].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76658ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels to binary (re-implement small mapping here)\n",
    "def map_to_binary(yarr):\n",
    "    y = np.array(yarr)\n",
    "    svals = [str(v).lower() for v in y[:1000]] if y.size>0 else []\n",
    "    if any('normal' in s for s in svals):\n",
    "        return np.array([0 if 'normal' in str(v).lower() else 1 for v in y], dtype=int)\n",
    "    try:\n",
    "        yi = y.astype(int)\n",
    "        maj = int(np.argmax(np.bincount(yi)))\n",
    "        return np.array([0 if int(v)==maj else 1 for v in yi], dtype=int)\n",
    "    except Exception:\n",
    "        try:\n",
    "            yf = y.astype(float)\n",
    "            return np.array([0 if float(v)==0.0 else 1 for v in yf], dtype=int)\n",
    "        except Exception:\n",
    "            first = y[0]\n",
    "            return np.array([0 if v==first else 1 for v in y], dtype=int)\n",
    "\n",
    "y_sample = map_to_binary(df_sample[label_col].values)\n",
    "df_sample['__y'] = y_sample\n",
    "print('Binary mapping: unique values ->', np.unique(y_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae2db1",
   "metadata": {},
   "source": [
    "## Class / attack distribution visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart + pie chart for class distribution\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = sns.countplot(x='__y', data=df_sample)\n",
    "ax.set_title('Binary class counts (sample)')\n",
    "plt.savefig(FIG_DIR / 'class_counts.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "if px is not None:\n",
    "    try:\n",
    "        fig = px.pie(df_sample, names='__y', title='Class distribution (sample)')\n",
    "        fig.write_html(str(FIG_DIR / 'class_distribution_pie.html'))\n",
    "        print('Wrote interactive pie to', FIG_DIR / 'class_distribution_pie.html')\n",
    "    except Exception as e:\n",
    "        print('Plotly pie failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab59c08",
   "metadata": {},
   "source": [
    "## Feature distributions for top permutation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose top features (from perm_top if available)\n",
    "if perm_top:\n",
    "    top_feats = perm_top[:10]\n",
    "else:\n",
    "    # fallback: pick numeric cols with highest variance\n",
    "    numcols = df_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    varr = df_sample[numcols].var().sort_values(ascending=False)\n",
    "    top_feats = varr.index[:10].tolist()\n",
    "\n",
    "print('Top features for distribution plots:', top_feats)\n",
    "\n",
    "for f in top_feats:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    if pd.api.types.is_numeric_dtype(df_sample[f]):\n",
    "        sns.kdeplot(data=df_sample, x=f, hue='__y', common_norm=False, fill=True)\n",
    "        plt.title(f'Density plot of {f} by class')\n",
    "    else:\n",
    "        sns.countplot(y=f, data=df_sample, order=df_sample[f].value_counts().index[:20])\n",
    "        plt.title(f'Value counts for {f}')\n",
    "    plt.tight_layout()\n",
    "    outp = FIG_DIR / f'feature_dist_{f.replace(' ', '_').strip()}.png'\n",
    "    plt.savefig(outp, dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af2fb6",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b20399",
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = df_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
    "corr = df_sample[numcols].corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.clustermap(corr, cmap='vlag', linewidths=.5, figsize=(12,12))\n",
    "plt.title('Feature correlation clustermap')\n",
    "plt.savefig(FIG_DIR / 'correlation_clustermap.png', dpi=150, bbox_inches='tight')\n",
    "# save top correlations to CSV\n",
    "corr_pairs = corr.abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "corr_pairs = corr_pairs[corr_pairs < 1.0] # drop self correlations\n",
    "corr_pairs.head(20).to_csv(FIG_DIR / 'top_correlations.csv')\n",
    "print('Saved top correlations to', FIG_DIR / 'top_correlations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81899cd5",
   "metadata": {},
   "source": [
    "## Pairplot of top features (small sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d47cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_sample = df_sample.sample(n=2000, random_state=42) if len(df_sample)>2000 else df_sample\n",
    "sns.pairplot(pair_sample[top_feats[:5]+['__y']], hue='__y', plot_kws={'alpha':0.5})\n",
    "plt.savefig(FIG_DIR / 'pairplot_top_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d17da",
   "metadata": {},
   "source": [
    "## Feature importance (model-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128eed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple RandomForest on a sample to compute feature importances (fast)\n",
    "feat_sample = df_sample.sample(n=50000, random_state=42) if len(df_sample)>50000 else df_sample\n",
    "X = feat_sample.select_dtypes(include=[np.number]).fillna(0)\n",
    "y = feat_sample['__y']\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "rf.fit(X, y)\n",
    "imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,6))\n",
    "imp[:30].plot(kind='bar')\n",
    "plt.title('RandomForest feature importances (sample)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'rf_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d8d5d",
   "metadata": {},
   "source": [
    "## PCA projection (2D & 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fabfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on scaled numeric features\n",
    "scaler = StandardScaler()\n",
    "Xnum = df_sample.select_dtypes(include=[np.number]).fillna(0)\n",
    "Xscaled = scaler.fit_transform(Xnum)\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "Xp = pca.fit_transform(Xscaled)\n",
    "print('Explained variance ratios (3 comps):', pca.explained_variance_ratio_)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=Xp[:,0], y=Xp[:,1], hue=df_sample['__y'], alpha=0.6, palette='Set1')\n",
    "plt.title(f'PCA 2D (explained var: {pca.explained_variance_ratio_[:2]})')\n",
    "plt.savefig(FIG_DIR / 'pca_2d.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "# interactive Plotly version (if available)\n",
    "if px is not None:\n",
    "    fig = px.scatter_3d(x=Xp[:,0], y=Xp[:,1], z=Xp[:,2], color=df_sample['__y'].astype(str), title='PCA 3D')\n",
    "    fig.write_html(str(FIG_DIR / 'pca_3d.html'))\n",
    "    print('Wrote PCA 3D interactive to', FIG_DIR / 'pca_3d.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a70ea",
   "metadata": {},
   "source": [
    "## t-SNE and UMAP projections (subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = df_sample.sample(n=10000, random_state=42) if len(df_sample)>10000 else df_sample\n",
    "Xsub = sub.select_dtypes(include=[np.number]).fillna(0)\n",
    "Xs = StandardScaler().fit_transform(Xsub)\n",
    "t0 = time.time()\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000, verbose=1)\n",
    "emb = tsne.fit_transform(Xs)\n",
    "print('t-SNE took', round(time.time()-t0,2),'s')\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=emb[:,0], y=emb[:,1], hue=sub['__y'], alpha=0.6, palette='Set1')\n",
    "plt.title('t-SNE (10k sample)')\n",
    "plt.savefig(FIG_DIR / 'tsne_2d.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "if umap is not None:\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "    emb_u = reducer.fit_transform(Xs)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=emb_u[:,0], y=emb_u[:,1], hue=sub['__y'], alpha=0.6, palette='Set1')\n",
    "    plt.title('UMAP (10k sample)')\n",
    "    plt.savefig(FIG_DIR / 'umap_2d.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd9ca86",
   "metadata": {},
   "source": [
    "## Confusion matrix, ROC and Precision-Recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict probabilities on the sample test split (or full if available)\n",
    "# Here we reuse df_sample as a proxy; in production use reserved test set.\n",
    "X_eval = df_sample.select_dtypes(include=[np.number]).fillna(0)\n",
    "try:\n",
    "    proba = clf.predict_proba(X_eval)[:,1]\n",
    "except Exception:\n",
    "    proba = clf.predict_proba(X_eval.values)[:,1]\n",
    "pred = (proba >= threshold).astype(int)\n",
    "cm = confusion_matrix(df_sample['__y'], pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion matrix (sample)')\n",
    "plt.savefig(FIG_DIR / 'confusion_matrix_sample.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "fpr, tpr, _ = roc_curve(df_sample['__y'], proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (sample)')\n",
    "plt.legend()\n",
    "plt.savefig(FIG_DIR / 'roc_curve_sample.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "precision, recall, _ = precision_recall_curve(df_sample['__y'], proba)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall (sample)')\n",
    "plt.savefig(FIG_DIR / 'pr_curve_sample.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b48c3d",
   "metadata": {},
   "source": [
    "## SHAP explanations (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "    shap_available = True\n",
    "except Exception as e:\n",
    "    shap_available = False\n",
    "    print('shap not available. To install: conda activate fruty-catboost && pip install shap')\n",
    "\n",
    "if shap_available:\n",
    "    # compute shap on a small sample\n",
    "    sample_shap = df_sample.sample(n=10000, random_state=42) if len(df_sample)>10000 else df_sample\n",
    "    Xsh = sample_shap.select_dtypes(include=[np.number]).fillna(0)\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    shap_values = explainer.shap_values(Xsh)\n",
    "    shap.summary_plot(shap_values, Xsh, show=False)\n",
    "    plt.savefig(FIG_DIR / 'shap_summary.png', dpi=150, bbox_inches='tight')\n",
    "    print('Saved SHAP summary to', FIG_DIR / 'shap_summary.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c3430",
   "metadata": {},
   "source": [
    "## Export & wrap-up\n",
    "Figures saved under `results/figs/`.\n",
    "Next steps: inspect top feature distributions (e.g., Destination Port) for leakage, run SHAP if available, and run full K-fold CV for final validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
